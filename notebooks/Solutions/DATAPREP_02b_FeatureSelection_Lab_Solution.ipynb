{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing features with low variance\n",
    "\n",
    "The VarianceThreshold function (import see below) alows you to remove features that have a variance in their values below a defined threshold\n",
    "\n",
    "Start with the data frame df defined below, and print the values of df before and after removing features with a variance below 0.2\n",
    "\n",
    "To select the features you need to fit your model first and then use a mask on the columns of the data frame\n",
    "\n",
    "Hint: Method get_support might be useful to apply the mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original data frame:\n",
      "    A  B  C\n",
      "0  0  0  1\n",
      "1  0  1  0\n",
      "2  1  0  0\n",
      "3  0  1  1\n",
      "4  0  1  0\n",
      "5  0  1  1\n",
      "Data frame without low variance features:\n",
      "    B  C\n",
      "0  0  1\n",
      "1  1  0\n",
      "2  0  0\n",
      "3  1  1\n",
      "4  1  0\n",
      "5  1  1\n"
     ]
    }
   ],
   "source": [
    "#Removing features with low variance\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "x = [[0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 1, 1], [0, 1, 0], [0, 1, 1]]\n",
    "df=pd.DataFrame(x,columns=['A','B','C'])\n",
    "print(\"\\nOriginal data frame:\\n\",df)\n",
    "\n",
    "sel = VarianceThreshold(threshold=(0.2))\n",
    "sel.fit(df)\n",
    "reduced_df=df[df.columns[sel.get_support(indices=True)]]\n",
    "\n",
    "print(\"Data frame without low variance features:\\n\",reduced_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter approaches for feature selection\n",
    "\n",
    "Select features using Mutual Information = Information Gain within the SelectKBest function\n",
    "\n",
    "Start by constructing a data frame from the load_digits dataset, columns should be index-named 'a1','a2',....'a63' + 'Label' \n",
    "\n",
    "Select the 10 best features and print the data frame header before and after selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data frame: <bound method NDFrame.head of        a1   a2    a3    a4    a5    a6   a7   a8   a9  a10  ...  a56  a57  \\\n",
      "0     0.0  0.0   5.0  13.0   9.0   1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "1     0.0  0.0   0.0  12.0  13.0   5.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "2     0.0  0.0   0.0   4.0  15.0  12.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "3     0.0  0.0   7.0  15.0  13.0   1.0  0.0  0.0  0.0  8.0  ...  0.0  0.0   \n",
      "4     0.0  0.0   0.0   1.0  11.0   0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "...   ...  ...   ...   ...   ...   ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "1792  0.0  0.0   4.0  10.0  13.0   6.0  0.0  0.0  0.0  1.0  ...  0.0  0.0   \n",
      "1793  0.0  0.0   6.0  16.0  13.0  11.0  1.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "1794  0.0  0.0   1.0  11.0  15.0   1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "1795  0.0  0.0   2.0  10.0   7.0   0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "1796  0.0  0.0  10.0  14.0   8.0   1.0  0.0  0.0  0.0  2.0  ...  0.0  0.0   \n",
      "\n",
      "      a58  a59   a60   a61   a62  a63  a64  Label  \n",
      "0     0.0  6.0  13.0  10.0   0.0  0.0  0.0    0.0  \n",
      "1     0.0  0.0  11.0  16.0  10.0  0.0  0.0    1.0  \n",
      "2     0.0  0.0   3.0  11.0  16.0  9.0  0.0    2.0  \n",
      "3     0.0  7.0  13.0  13.0   9.0  0.0  0.0    3.0  \n",
      "4     0.0  0.0   2.0  16.0   4.0  0.0  0.0    4.0  \n",
      "...   ...  ...   ...   ...   ...  ...  ...    ...  \n",
      "1792  0.0  2.0  14.0  15.0   9.0  0.0  0.0    9.0  \n",
      "1793  0.0  6.0  16.0  14.0   6.0  0.0  0.0    0.0  \n",
      "1794  0.0  2.0   9.0  13.0   6.0  0.0  0.0    8.0  \n",
      "1795  0.0  5.0  12.0  16.0  12.0  0.0  0.0    9.0  \n",
      "1796  1.0  8.0  12.0  14.0  12.0  1.0  0.0    8.0  \n",
      "\n",
      "[1797 rows x 65 columns]>\n",
      "Reduced data frame (first rows): \n",
      "        a21   a22   a27   a29  a34   a35  a39   a43   a44   a62  Label\n",
      "0      0.0  11.0  12.0   0.0  5.0   8.0  8.0  11.0   0.0   0.0    0.0\n",
      "1     16.0   6.0  15.0  16.0  0.0   1.0  0.0   1.0  16.0  10.0    1.0\n",
      "2      8.0  16.0   1.0  15.0  1.0   8.0  0.0  16.0  16.0  16.0    2.0\n",
      "3     13.0   0.0   2.0  11.0  0.0   0.0  1.0   0.0   0.0   9.0    3.0\n",
      "4      6.0   2.0   7.0   0.0  5.0  16.0  6.0  15.0  16.0   4.0    4.0\n",
      "...    ...   ...   ...   ...  ...   ...  ...   ...   ...   ...    ...\n",
      "1792   3.0  16.0  12.0  16.0  0.0   0.0  8.0   0.0   0.0   9.0    9.0\n",
      "1793   0.0  13.0  16.0   0.0  8.0  16.0  6.0  16.0   7.0   6.0    0.0\n",
      "1794  10.0  16.0   8.0  16.0  0.0   9.0  0.0  16.0  14.0   6.0    8.0\n",
      "1795   3.0  16.0  16.0   7.0  0.0   5.0  4.0   0.0   0.0  12.0    9.0\n",
      "1796   8.0  15.0   5.0  16.0  0.0  12.0  0.0  16.0   6.0  12.0    8.0\n",
      "\n",
      "[1797 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "#Filter approaches\n",
    "#Univariate feature selection\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "#Load data into array\n",
    "x = load_digits()\n",
    "\n",
    "#Construct data frame\n",
    "column_names=['a'+str(i) for i in range(1, x.data.shape[1]+1)]\n",
    "column_names.append('Label')\n",
    "df=pd.DataFrame(np.column_stack([x.data,x.target]),columns=column_names)\n",
    "print('Original data frame:',df.head)\n",
    "\n",
    "#Select 10 features using Mutual Information = Information Gain\n",
    "sel = SelectKBest(mutual_info_classif, k=10)\n",
    "sel.fit(df.loc[:,'a1':'a63'], df['Label'])\n",
    "remaining_columns= df.columns[sel.get_support(indices=True)] \n",
    "remaining_columns= remaining_columns.insert(len(remaining_columns),'Label')\n",
    "reduced_df=df[remaining_columns]\n",
    "\n",
    "print('Reduced data frame (first rows): \\n',reduced_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursive Feature Elimination (RFE)\n",
    "\n",
    "Given an external estimator that assigns weights to features (e.g., the coefficients of a linear model), recursive feature elimination (RFE) is to select features by recursively considering smaller and smaller sets of features. First, the estimator is trained on the initial set of features and the importance of each feature is obtained either through a coef_ attribute or through a feature_importances_ attribute. Then, the least important features are pruned from current set of features.That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached.\n",
    "\n",
    "Based on the given data frame, first create your RFE object. Use \"SVC\" as an estimator and restrict to 2 features. Fit the RFE object.\n",
    "\n",
    "Now we fill select two features based on the fitted RFE object.\n",
    "\n",
    "First, create a column mask based on the attribute rfe.support_. The column mask should be an extension of this attribute to mask the features AND the label (label should always be selected)\n",
    "\n",
    "Second, use your column mask to mask the df_columns list and store the result in variable reduced_iris_features\n",
    "\n",
    "Third, use reduced_iris_features as an index on the data frame to do the final feature selection and store the result in reduced_df\n",
    "\n",
    "Finally, print reduced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Iris Data Set:\n",
      "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                  5.1               3.5                1.4               0.2   \n",
      "1                  4.9               3.0                1.4               0.2   \n",
      "2                  4.7               3.2                1.3               0.2   \n",
      "3                  4.6               3.1                1.5               0.2   \n",
      "4                  5.0               3.6                1.4               0.2   \n",
      "..                 ...               ...                ...               ...   \n",
      "145                6.7               3.0                5.2               2.3   \n",
      "146                6.3               2.5                5.0               1.9   \n",
      "147                6.5               3.0                5.2               2.0   \n",
      "148                6.2               3.4                5.4               2.3   \n",
      "149                5.9               3.0                5.1               1.8   \n",
      "\n",
      "         Label  \n",
      "0       setosa  \n",
      "1       setosa  \n",
      "2       setosa  \n",
      "3       setosa  \n",
      "4       setosa  \n",
      "..         ...  \n",
      "145  virginica  \n",
      "146  virginica  \n",
      "147  virginica  \n",
      "148  virginica  \n",
      "149  virginica  \n",
      "\n",
      "[150 rows x 5 columns]\n",
      "Reduced_iris_features:  ['petal length (cm)', 'petal width (cm)', 'Label']\n",
      "\n",
      "Iris Data Set reduced to  2  features: \n",
      "      petal length (cm)  petal width (cm)      Label\n",
      "0                  1.4               0.2     setosa\n",
      "1                  1.4               0.2     setosa\n",
      "2                  1.3               0.2     setosa\n",
      "3                  1.5               0.2     setosa\n",
      "4                  1.4               0.2     setosa\n",
      "..                 ...               ...        ...\n",
      "145                5.2               2.3  virginica\n",
      "146                5.0               1.9  virginica\n",
      "147                5.2               2.0  virginica\n",
      "148                5.4               2.3  virginica\n",
      "149                5.1               1.8  virginica\n",
      "\n",
      "[150 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#Wrapper approaches\n",
    "#Backward elimination using Recursive feature eliminationÂ¶\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import feature_selection\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "x_y= np.concatenate((x.reshape(150,4),y.reshape(150,1)),1)\n",
    "#print(x_y)\n",
    "#print(iris.target_names)\n",
    "\n",
    "#Create column list\n",
    "df_columns=iris.feature_names\n",
    "df_columns.append(\"Label\")\n",
    "#Create PANDAS data frame\n",
    "df = pd.DataFrame(x_y,columns=df_columns)\n",
    "#Map label index to label name\n",
    "df['Label']=df['Label'].map(lambda x: iris.target_names[int(x)])\n",
    "print(\"\\nOriginal Iris Data Set:\")\n",
    "print(df)\n",
    "\n",
    "#Create the RFE object and rank features\n",
    "num_features=2\n",
    "svc = SVC(kernel=\"linear\", C=1)\n",
    "rfe = feature_selection.RFE(estimator=svc, n_features_to_select=num_features, step=1)\n",
    "rfe.fit(x, y)\n",
    "#print(\"Selected features will have a ranking=1 and support=TRUE\")\n",
    "#print(iris.feature_names,\" \",rfe.ranking_,\" \",rfe.support_)\n",
    "#print(x.shape)\n",
    "\n",
    "#extend column-mask by one column for the label (always true)\n",
    "column_mask=np.append(rfe.support_,True)\n",
    "#use list column_mask to mask df-columns list\n",
    "reduced_iris_features = [df_columns[i] for i in range(len(df_columns)) if column_mask[i]]\n",
    "print(\"Reduced_iris_features: \",reduced_iris_features)\n",
    "# use reduced_iris_features to reduce the data frame\n",
    "reduced_df=df[reduced_iris_features]\n",
    "\n",
    "print(\"\\nIris Data Set reduced to \",num_features,\" features: \\n\",reduced_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
